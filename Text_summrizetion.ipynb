{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1s6jzUFi7WO66ovV8U6vXDYEZXFxWKxP0",
      "authorship_tag": "ABX9TyPfJv8UIjWUwocIjmd6rl03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/showmik121/Genetivie_AI/blob/main/Text_summrizetion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text summerization"
      ],
      "metadata": {
        "id": "ASVRAqy-Opcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step->\n",
        "\n",
        "1.pakage and libaries install\n",
        "2.dataset_load\n",
        "3.tokenizer\n",
        "4.Map->use ->transformation\n",
        "5.Model load->parametter\n",
        "6.Model Training\n",
        "7.Evalution\n",
        "8.Save model\n",
        "9.check"
      ],
      "metadata": {
        "id": "FrL7AxjtOzv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cl7ZLXtN66P"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade transformers[sentencepiece] datasets sacrebleu rouge_score py7zr --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breakdown command**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   pip install --upgrade\n",
        "\n",
        "\n",
        "\n",
        "Ensures that the latest version of the packages is installed.\n",
        "\n",
        "2.   transformers[sentencepiece]\n",
        "\n",
        "\n",
        "Installs the Hugging Face transformers library.\n",
        "The [sentencepiece] extra is needed for models like T5, BART, and MarianMT, which use SentencePiece tokenization.\n",
        "3.   datasets\n",
        "\n",
        "Installs Hugging Face’s datasets library for loading and processing datasets like IMDB, SQuAD, etc.\n",
        "4.sacrebleu\n",
        "\n",
        "Used for BLEU score evaluation in machine translation tasks.\n",
        "5. rouge_score\n",
        "\n",
        "Used to calculate ROUGE scores for summarization tasks.\n",
        "6.   py7zr\n",
        "\n",
        "Supports .7z compression, which some datasets use\n",
        "7.   --no-cache-dir\n",
        "\n",
        "\n",
        "Prevents storing downloaded packages in cache (useful if storage is limited).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gx6CBP-fWXku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "u1BjKR98Yzg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updates the Hugging Face accelerate library, which optimizes model training and inference on GPUs/TPUs.\n",
        "Useful when working with distributed training.\n",
        "\n",
        "If models are not using GPUs efficiently, a fresh accelerate install may help"
      ],
      "metadata": {
        "id": "x6hPiJN_c1Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "N1w5fARCd32x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "d8fzX2D_eE_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "used for evaluating machine learning models in NLP and other domains. Easy integration with datasets and transformers for NLP tasks."
      ],
      "metadata": {
        "id": "GJS7w1dReaUI"
      }
    },
    {
      "source": [
        "!pip install --upgrade datasets evaluate"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1vpPcVtuicUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "WnaXDgAkgTta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline,set_seed\n",
        "from datasets import load_dataset,load_from_disk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "-lRbByovgCGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk (Natural Language Toolkit) is used for NLP tasks like tokenization.\n",
        "\n",
        "**AutoModelForSeq2SeqLM is used for text generation tasks** **bold text**\n",
        "\n",
        "Used in Summarization, Translation, and Paraphrasing\n",
        "\n",
        "nltk.download(\"punkt\")-> Splits a paragraph into sentences."
      ],
      "metadata": {
        "id": "feZtvISOjm5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_RY39Kw-mVVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre trained model"
      ],
      "metadata": {
        "id": "mphp5tA6nnFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ckpt = \"google/pegasus-xsum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "#"
      ],
      "metadata": {
        "id": "fNvM8J0kncEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data set- 1.id  2.dialoge  3.summary"
      ],
      "metadata": {
        "id": "HOpMUfTCX8cJ"
      }
    },
    {
      "source": [
        "!pip install py7zr"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WOyO37Vf6QCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum=load_dataset('samsum')\n",
        "dataset_samsum"
      ],
      "metadata": {
        "id": "Tz8bhXjOXRp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train']['dialogue'][0]"
      ],
      "metadata": {
        "id": "665XLUYaZMJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train'][0]['summary']"
      ],
      "metadata": {
        "id": "o5LDEETWaNQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_lengths=[len(dataset_samsum[split]) for split in dataset_samsum]"
      ],
      "metadata": {
        "id": "a4aXsVk9auFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Order of values: [train_size, validation_size, test_size]"
      ],
      "metadata": {
        "id": "TfpTtafXfYpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Split length: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")"
      ],
      "metadata": {
        "id": "-j8CU7Ssa7jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   split_lengths gives dataset size per split.\n",
        "2.   dataset['train'].column_names lists dataset features\n",
        "\n"
      ],
      "metadata": {
        "id": "g7BrC7WncPna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_samsum['test'][0]['dialogue'])\n",
        "print(dataset_samsum['test'][0]['summary'])"
      ],
      "metadata": {
        "id": "MOZN-pP2hNjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization-**label data**"
      ],
      "metadata": {
        "id": "Byug9q3LiHek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_feature(example_batch):\n",
        "  input_encodings=tokenizer(example_batch['dialogue'],max_length=1024,truncation=True)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings=tokenizer(example_batch['summary'],max_length=128,truncation=True)\n",
        "\n",
        "\n",
        "  return {\n",
        "      'input_ids':input_encodings['input_ids'],\n",
        "      'attention_mask':input_encodings['attention_mask'],\n",
        "      'labels':target_encodings['input_ids']\n",
        "  }"
      ],
      "metadata": {
        "id": "auKzbPxxiNCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(truncation=True) Prevents overflow errors when input text is longer than the model’s max length"
      ],
      "metadata": {
        "id": "_Yg0SoScl1zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation-**mapping**"
      ],
      "metadata": {
        "id": "o3FxES4cq2un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt=dataset_samsum.map(convert_examples_to_feature,batched=True)"
      ],
      "metadata": {
        "id": "I-3G2GeMp6Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch processing"
      ],
      "metadata": {
        "id": "ll14CiRVvywl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']['input_ids'][1]"
      ],
      "metadata": {
        "id": "gGiPOk2nrRoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']['attention_mask'][1]"
      ],
      "metadata": {
        "id": "9R98MK8EvfXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**data collator**"
      ],
      "metadata": {
        "id": "wuZjWXL6wGC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2aeq_data_collator=DataCollatorForSeq2Seq(tokenizer,model=model)"
      ],
      "metadata": {
        "id": "7-npO9ZrwQe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataCollatorForSeq2Seq-Ensures correct label padding\n",
        "\n",
        "Ensures correct input format for Seq2Seq models like T5, BART, Pegasus.\n",
        "\n",
        "Helps when using Trainer() for model training."
      ],
      "metadata": {
        "id": "j9RTY5ajyEXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranning"
      ],
      "metadata": {
        "id": "uXsqf0aZy6Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "id": "s8nNwbL4zDJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_args=TrainingArguments(\n",
        "    output_dir='pegasus-samsum',num_train_epochs=1,warmup_steps=500,\n",
        "    per_device_train_batch_size=1,per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01,logging_steps=10,\n",
        "    evaluation_strategy='steps',eval_steps=500,save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "SUlbQyyuzLiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2aeq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt['train'],\n",
        "                  eval_dataset=dataset_samsum_pt['validation'])"
      ],
      "metadata": {
        "id": "-wMLQmHwz5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "8Z29zsnD19qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bNQpN1is6eXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_sized_chunks(list_of_elements,batch_size):\n",
        "  for i in range(0,len(list_of_elements),batch_size):\n",
        "    yield list_of_elements[i:i+batch_size]"
      ],
      "metadata": {
        "id": "Qf5CYcRh6uiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
        "                                batch_size=16,\n",
        "                                column_text=\"article\",\n",
        "                                column_summary=\"highlights\",\n",
        "                                device=None): # Change 1: Remove device=device and add device=None\n",
        "    if device is None: # Change 2: Check if device is provided and assign if not\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "            zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        input_data = tokenizer(article_batch, max_length=1024, truncation=True,\n",
        "                            padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=input_data[\"input_ids\"].to(device),\n",
        "                                  attention_mask=input_data[\"attention_mask\"].to(device),\n",
        "                                  length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                            clean_up_tokenization_spaces=True)\n",
        "                            for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    score = metric.compute()\n",
        "    return score"
      ],
      "metadata": {
        "id": "Mxl9B95-C3vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names=[\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]\n",
        "rouge_metrix=evaluate.load('rouge')"
      ],
      "metadata": {
        "id": "z1KGyMI3Dn1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "\n",
        "# calculate metrix on test dataset\n",
        "score = calculate_metric_on_test_ds(\n",
        "    dataset_samsum['test'][0:10], rouge_metrix, model, tokenizer, batch_size=2, column_text='dialogue', column_summary='summary'\n",
        ")\n",
        "rouge_dict=dict((rn,score[rn]) for rn in rouge_names)\n",
        "\n",
        "# create data frame on display\n",
        "pd.DataFrame(rouge_dict,index=[f'pegasus'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3qL746pTHt5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "iWMPpDm8KF8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model_pegasus.save_pretrined(\"pegasus-samsum\")"
      ],
      "metadata": {
        "id": "mxJSxFBjKP4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "id": "rOEvdjLaKm1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load"
      ],
      "metadata": {
        "id": "m0g1yDedLT2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/tokenizer\")"
      ],
      "metadata": {
        "id": "J11xbCxpLdS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}"
      ],
      "metadata": {
        "id": "apZwSoz1LvgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test=s=dataset_samsum[\"test\"][0][\"dialogue\"]\n",
        "reference=dataset_samsum[\"test\"][0][\"summary\"]"
      ],
      "metadata": {
        "id": "fFdQWl_LL1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe=pipeline(\"summarization\",model=\"pegasus-samsum\",tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "o0pz-cazMPkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dialogue\")\n",
        "print(sample_test)\n",
        "\n",
        "print(\"\\nReference Summary\")\n",
        "print(reference)\n",
        "\n",
        "print(\"\\nModel Summary\")\n",
        "print(pipe(sample_test, **gen_kwargs)[0][\"summary_text\"])"
      ],
      "metadata": {
        "id": "1nXxuXXEMcM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}