{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1s6jzUFi7WO66ovV8U6vXDYEZXFxWKxP0",
      "authorship_tag": "ABX9TyPfJv8UIjWUwocIjmd6rl03",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/showmik121/Genetivie_AI/blob/main/Text_summrizetion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text summerization"
      ],
      "metadata": {
        "id": "ASVRAqy-Opcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "step->\n",
        "\n",
        "1.pakage and libaries install\n",
        "2.dataset_load\n",
        "3.tokenizer\n",
        "4.Map->use ->transformation\n",
        "5.Model load->parametter\n",
        "6.Model Training\n",
        "7.Evalution\n",
        "8.Save model\n",
        "9.check"
      ],
      "metadata": {
        "id": "FrL7AxjtOzv-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cl7ZLXtN66P"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade transformers[sentencepiece] datasets sacrebleu rouge_score py7zr --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breakdown command**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1.   pip install --upgrade\n",
        "\n",
        "\n",
        "\n",
        "Ensures that the latest version of the packages is installed.\n",
        "\n",
        "2.   transformers[sentencepiece]\n",
        "\n",
        "\n",
        "Installs the Hugging Face transformers library.\n",
        "The [sentencepiece] extra is needed for models like T5, BART, and MarianMT, which use SentencePiece tokenization.\n",
        "3.   datasets\n",
        "\n",
        "Installs Hugging Faceâ€™s datasets library for loading and processing datasets like IMDB, SQuAD, etc.\n",
        "4.sacrebleu\n",
        "\n",
        "Used for BLEU score evaluation in machine translation tasks.\n",
        "5. rouge_score\n",
        "\n",
        "Used to calculate ROUGE scores for summarization tasks.\n",
        "6.   py7zr\n",
        "\n",
        "Supports .7z compression, which some datasets use\n",
        "7.   --no-cache-dir\n",
        "\n",
        "\n",
        "Prevents storing downloaded packages in cache (useful if storage is limited).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gx6CBP-fWXku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip uninstall -y transformers accelerate\n",
        "!pip install transformers accelerate"
      ],
      "metadata": {
        "id": "u1BjKR98Yzg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updates the Hugging Face accelerate library, which optimizes model training and inference on GPUs/TPUs.\n",
        "Useful when working with distributed training.\n",
        "\n",
        "If models are not using GPUs efficiently, a fresh accelerate install may help"
      ],
      "metadata": {
        "id": "x6hPiJN_c1Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets"
      ],
      "metadata": {
        "id": "N1w5fARCd32x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "d8fzX2D_eE_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "used for evaluating machine learning models in NLP and other domains. Easy integration with datasets and transformers for NLP tasks."
      ],
      "metadata": {
        "id": "GJS7w1dReaUI"
      }
    },
    {
      "source": [
        "!pip install --upgrade datasets evaluate"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "1vpPcVtuicUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "WnaXDgAkgTta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline,set_seed\n",
        "from datasets import load_dataset,load_from_disk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "-lRbByovgCGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk (Natural Language Toolkit) is used for NLP tasks like tokenization.\n",
        "\n",
        "**AutoModelForSeq2SeqLM is used for text generation tasks** **bold text**\n",
        "\n",
        "Used in Summarization, Translation, and Paraphrasing\n",
        "\n",
        "nltk.download(\"punkt\")-> Splits a paragraph into sentences."
      ],
      "metadata": {
        "id": "feZtvISOjm5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "_RY39Kw-mVVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre trained model"
      ],
      "metadata": {
        "id": "mphp5tA6nnFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ckpt = \"google/pegasus-xsum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "#"
      ],
      "metadata": {
        "id": "fNvM8J0kncEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data set- 1.id  2.dialoge  3.summary"
      ],
      "metadata": {
        "id": "HOpMUfTCX8cJ"
      }
    },
    {
      "source": [
        "!pip install py7zr"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WOyO37Vf6QCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum=load_dataset('samsum')\n",
        "dataset_samsum"
      ],
      "metadata": {
        "id": "Tz8bhXjOXRp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train']['dialogue'][0]"
      ],
      "metadata": {
        "id": "665XLUYaZMJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum['train'][0]['summary']"
      ],
      "metadata": {
        "id": "o5LDEETWaNQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_lengths=[len(dataset_samsum[split]) for split in dataset_samsum]"
      ],
      "metadata": {
        "id": "a4aXsVk9auFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Order of values: [train_size, validation_size, test_size]"
      ],
      "metadata": {
        "id": "TfpTtafXfYpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Split length: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")"
      ],
      "metadata": {
        "id": "-j8CU7Ssa7jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   split_lengths gives dataset size per split.\n",
        "2.   dataset['train'].column_names lists dataset features\n",
        "\n"
      ],
      "metadata": {
        "id": "g7BrC7WncPna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_samsum['test'][0]['dialogue'])\n",
        "print(dataset_samsum['test'][0]['summary'])"
      ],
      "metadata": {
        "id": "MOZN-pP2hNjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization-**label data**"
      ],
      "metadata": {
        "id": "Byug9q3LiHek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_feature(example_batch):\n",
        "  input_encodings=tokenizer(example_batch['dialogue'],max_length=1024,truncation=True)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings=tokenizer(example_batch['summary'],max_length=128,truncation=True)\n",
        "\n",
        "\n",
        "  return {\n",
        "      'input_ids':input_encodings['input_ids'],\n",
        "      'attention_mask':input_encodings['attention_mask'],\n",
        "      'labels':target_encodings['input_ids']\n",
        "  }"
      ],
      "metadata": {
        "id": "auKzbPxxiNCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(truncation=True) Prevents overflow errors when input text is longer than the modelâ€™s max length"
      ],
      "metadata": {
        "id": "_Yg0SoScl1zc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformation-**mapping**"
      ],
      "metadata": {
        "id": "o3FxES4cq2un"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt=dataset_samsum.map(convert_examples_to_feature,batched=True)"
      ],
      "metadata": {
        "id": "I-3G2GeMp6Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch processing"
      ],
      "metadata": {
        "id": "ll14CiRVvywl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']['input_ids'][1]"
      ],
      "metadata": {
        "id": "gGiPOk2nrRoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum_pt['train']['attention_mask'][1]"
      ],
      "metadata": {
        "id": "9R98MK8EvfXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**data collator**"
      ],
      "metadata": {
        "id": "wuZjWXL6wGC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2aeq_data_collator=DataCollatorForSeq2Seq(tokenizer,model=model)"
      ],
      "metadata": {
        "id": "7-npO9ZrwQe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataCollatorForSeq2Seq-Ensures correct label padding\n",
        "\n",
        "Ensures correct input format for Seq2Seq models like T5, BART, Pegasus.\n",
        "\n",
        "Helps when using Trainer() for model training."
      ],
      "metadata": {
        "id": "j9RTY5ajyEXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranning"
      ],
      "metadata": {
        "id": "uXsqf0aZy6Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer"
      ],
      "metadata": {
        "id": "s8nNwbL4zDJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_args=TrainingArguments(\n",
        "    output_dir='pegasus-samsum',num_train_epochs=1,warmup_steps=500,\n",
        "    per_device_train_batch_size=1,per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01,logging_steps=10,\n",
        "    evaluation_strategy='steps',eval_steps=500,save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ],
      "metadata": {
        "id": "SUlbQyyuzLiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2aeq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt['train'],\n",
        "                  eval_dataset=dataset_samsum_pt['validation'])"
      ],
      "metadata": {
        "id": "-wMLQmHwz5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "8Z29zsnD19qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "bNQpN1is6eXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch_sized_chunks(list_of_elements,batch_size):\n",
        "  for i in range(0,len(list_of_elements),batch_size):\n",
        "    yield list_of_elements[i:i+batch_size]"
      ],
      "metadata": {
        "id": "Qf5CYcRh6uiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
        "                                batch_size=16,\n",
        "                                column_text=\"article\",\n",
        "                                column_summary=\"highlights\",\n",
        "                                device=None): # Change 1: Remove device=device and add device=None\n",
        "    if device is None: # Change 2: Check if device is provided and assign if not\n",
        "        import torch\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    article_batches = list(generate_batch_sized_chunks(dataset[column_text], batch_size))\n",
        "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "    for article_batch, target_batch in tqdm(\n",
        "            zip(article_batches, target_batches), total=len(article_batches)):\n",
        "\n",
        "        input_data = tokenizer(article_batch, max_length=1024, truncation=True,\n",
        "                            padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = model.generate(input_ids=input_data[\"input_ids\"].to(device),\n",
        "                                  attention_mask=input_data[\"attention_mask\"].to(device),\n",
        "                                  length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                            clean_up_tokenization_spaces=True)\n",
        "                            for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "\n",
        "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    score = metric.compute()\n",
        "    return score"
      ],
      "metadata": {
        "id": "Mxl9B95-C3vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_names=[\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]\n",
        "rouge_metrix=evaluate.load('rouge')"
      ],
      "metadata": {
        "id": "z1KGyMI3Dn1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "\n",
        "# calculate metrix on test dataset\n",
        "score = calculate_metric_on_test_ds(\n",
        "    dataset_samsum['test'][0:10], rouge_metrix, model, tokenizer, batch_size=2, column_text='dialogue', column_summary='summary'\n",
        ")\n",
        "rouge_dict=dict((rn,score[rn]) for rn in rouge_names)\n",
        "\n",
        "# create data frame on display\n",
        "pd.DataFrame(rouge_dict,index=[f'pegasus'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "3qL746pTHt5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "iWMPpDm8KF8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model_pegasus.save_pretrined(\"pegasus-samsum\")"
      ],
      "metadata": {
        "id": "mxJSxFBjKP4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "id": "rOEvdjLaKm1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load"
      ],
      "metadata": {
        "id": "m0g1yDedLT2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/tokenizer\")"
      ],
      "metadata": {
        "id": "J11xbCxpLdS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}"
      ],
      "metadata": {
        "id": "apZwSoz1LvgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test=s=dataset_samsum[\"test\"][0][\"dialogue\"]\n",
        "reference=dataset_samsum[\"test\"][0][\"summary\"]"
      ],
      "metadata": {
        "id": "fFdQWl_LL1VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe=pipeline(\"summarization\",model=\"pegasus-samsum\",tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "o0pz-cazMPkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"dialogue\")\n",
        "print(sample_test)\n",
        "\n",
        "print(\"\\nReference Summary\")\n",
        "print(reference)\n",
        "\n",
        "print(\"\\nModel Summary\")\n",
        "print(pipe(sample_test, **gen_kwargs)[0][\"summary_text\"])"
      ],
      "metadata": {
        "id": "1nXxuXXEMcM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}